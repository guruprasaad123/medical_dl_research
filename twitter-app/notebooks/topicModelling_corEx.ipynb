{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buckaroo/nlp/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (27,194,197) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @KirkKus: Indirect cost of the UK being in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIDEO: Sturgeon on post-election deals http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @LabourEoin: The economy was growing 3 time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @GregLauder: the UKIP east lothian candidat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @thesundaypeople: UKIP's housing spokesman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @Nigel_Farage: Make sure you tune in to #As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @joannetallis: Ed Milliband is an embarrass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @abstex: The FT is backing the Tories. On a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @NivenJ1: “@George_Osborne: Ed Miliband pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LOLZ to Trickle Down Wealth. It's never trickl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @KirkKus: Indirect cost of the UK being in ...\n",
       "1  VIDEO: Sturgeon on post-election deals http://...\n",
       "2  RT @LabourEoin: The economy was growing 3 time...\n",
       "3  RT @GregLauder: the UKIP east lothian candidat...\n",
       "4  RT @thesundaypeople: UKIP's housing spokesman ...\n",
       "5  RT @Nigel_Farage: Make sure you tune in to #As...\n",
       "6  RT @joannetallis: Ed Milliband is an embarrass...\n",
       "7  RT @abstex: The FT is backing the Tories. On a...\n",
       "8  RT @NivenJ1: “@George_Osborne: Ed Miliband pro...\n",
       "9  LOLZ to Trickle Down Wealth. It's never trickl..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj = {}\n",
    "\n",
    "df = pd.read_csv('./tweets.csv')\n",
    "obj['text'] = df['text']\n",
    "dataframe = pd.DataFrame(obj)\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "9006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=.5,\n",
    "    min_df=10,\n",
    "    max_features=None,\n",
    "    ngram_range=(1, 2),\n",
    "    norm=None,\n",
    "    binary=True,\n",
    "    use_idf=False,\n",
    "    sublinear_tf=False\n",
    ")\n",
    "vectorizer = vectorizer.fit(dataframe['text'])\n",
    "tfidf = vectorizer.transform(dataframe['text'])\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab[0])\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corextopic import corextopic as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = []\n",
    "model = ct.Corex(n_hidden=4, seed=42)\n",
    "model = model.fit(\n",
    "    tfidf,\n",
    "    words=vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: rt nicolasturgeon, nicolasturgeon if, will definitely, we will, definitely need, protect sco, is going, need lots, in rather, snp we\n",
      "Topic #2: tories claiming, claiming, preoccupied, is preoccupied, in support, preoccupied inequality, inequality the, wrote it, who wrote, claiming miliband\n",
      "Topic #3: says he, are all, never forgive, says, you hear, off the, forgive, into, off, into new\n",
      "Topic #4: snp, with, rather, with snp, deal, let, work with, work, deal with, tories in\n"
     ]
    }
   ],
   "source": [
    "for i, topic_ngrams in enumerate(model.get_topics(n_words=10)):\n",
    "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
    "    print(\"Topic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchors designed to nudge the model towards measuring specific genres\n",
    "anchors = [\n",
    "    [\"money\",\"fund\"],\n",
    "    [\"emergency\"],\n",
    "    [\"recovered\"],\n",
    "    [\"treatment\"]\n",
    "]\n",
    "anchors = [\n",
    "    [a for a in topic if a in vocab]\n",
    "    for topic in anchors\n",
    "]\n",
    "\n",
    "model = ct.Corex(n_hidden=4, seed=42)\n",
    "model = model.fit(\n",
    "    tfidf,\n",
    "    words=vocab,\n",
    "    anchors=anchors, # Pass the anchors in here\n",
    "    anchor_strength=3 # Tell the model how much it should rely on the anchors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: is preoccupied, tommy_colc, preoccupied, in support, who wrote, preoccupied inequality, rt tommy_colc, inequality the, wrote it, claiming miliband\n",
      "Topic #2: rather, with, let, than work, work with, than, work, let tories, tories in, with snp\n",
      "Topic #3: says he, global financial, caused global, thus caused, thomasmessenger for, caused, and thus, ahem http, crisis ahem, thomasmessenger\n",
      "Topic #4: http, http co, co, financial, bbcqt http, david cameron, david, cameron\n"
     ]
    }
   ],
   "source": [
    "for i, topic_ngrams in enumerate(model.get_topics(n_words=10)):\n",
    "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
    "    print(\"Topic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_topic(arr=[]):\n",
    "    array = \"\"\n",
    "    for s in arr:\n",
    "        array+=s+\" \"\n",
    "        break\n",
    "    \n",
    "    return array   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1)\n",
      "(20000, 4)\n"
     ]
    }
   ],
   "source": [
    "topic_df = pd.DataFrame(\n",
    "    model.transform(tfidf), \n",
    "    #columns=[\"topic_{}\".format(i+1) for i in range(4)]\n",
    "    columns=  [\"money\",\"emergency\",\"recovered\",\"treatment\"]\n",
    ").astype(float)\n",
    "\n",
    "\n",
    "topic_df.index = dataframe.index\n",
    "\n",
    "print(dataframe.shape)\n",
    "print(topic_df.shape)\n",
    "\n",
    "topic_df\n",
    "\n",
    "final = pd.concat([dataframe, topic_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>money</th>\n",
       "      <th>emergency</th>\n",
       "      <th>recovered</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15119</th>\n",
       "      <td>RT @STUD6699: Nigel Farage says that homosexua...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>RT @UKIPEaling: Nigel Farage speaking with con...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>@ukmarkus http://t.co/WkfVKwHgED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>RT @A_Liberty_Rebel: Only regret at #BBCQT is ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>#bbcqt I'm surprised Cameron only got 44%. The...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>RT @UKIP: 70% of Britons support an Australian...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15774</th>\n",
       "      <td>RT @ad5red: @Nigel_Farage Different class toni...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14655</th>\n",
       "      <td>RT @NicolaSturgeon: If Miliband is going to le...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16025</th>\n",
       "      <td>Spot on Alison Parr; he did a fine job; unruff...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14871</th>\n",
       "      <td>RT @stewartbremner: The Oh-Dear Hunter is play...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  money  emergency  \\\n",
       "15119  RT @STUD6699: Nigel Farage says that homosexua...    0.0        0.0   \n",
       "12499  RT @UKIPEaling: Nigel Farage speaking with con...    0.0        0.0   \n",
       "10326                   @ukmarkus http://t.co/WkfVKwHgED    0.0        0.0   \n",
       "238    RT @A_Liberty_Rebel: Only regret at #BBCQT is ...    0.0        0.0   \n",
       "1943   #bbcqt I'm surprised Cameron only got 44%. The...    0.0        0.0   \n",
       "...                                                  ...    ...        ...   \n",
       "7762   RT @UKIP: 70% of Britons support an Australian...    0.0        0.0   \n",
       "15774  RT @ad5red: @Nigel_Farage Different class toni...    0.0        0.0   \n",
       "14655  RT @NicolaSturgeon: If Miliband is going to le...    0.0        1.0   \n",
       "16025  Spot on Alison Parr; he did a fine job; unruff...    0.0        0.0   \n",
       "14871  RT @stewartbremner: The Oh-Dear Hunter is play...    0.0        1.0   \n",
       "\n",
       "       recovered  treatment  \n",
       "15119        1.0        0.0  \n",
       "12499        0.0        0.0  \n",
       "10326        0.0        1.0  \n",
       "238          0.0        0.0  \n",
       "1943         0.0        1.0  \n",
       "...          ...        ...  \n",
       "7762         0.0        1.0  \n",
       "15774        0.0        0.0  \n",
       "14655        0.0        0.0  \n",
       "16025        0.0        0.0  \n",
       "14871        0.0        1.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.sample(100, random_state=92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 49894  100 49894    0     0  16252      0  0:00:03  0:00:03 --:--:-- 16252\n"
     ]
    }
   ],
   "source": [
    "! curl -L -o result.json http://ec2-13-232-219-139.ap-south-1.compute.amazonaws.com:4000/api/corona/0/9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .  RT @zeitonline: #China | s leadership wants to finally conquer #Hongkong | s democracy in the shadow of #Corona: @agoerlach on the future of the S…\n",
      "1 .  RT @zarazettirazr: About debt debt debt, blaming corona and impeachment by @RamliRizal\n",
      "#ILCCrisis Threatening https://t.co/i2UBdw5b…\n",
      "2 .  Rumors from North Korea that the Great Leader would have Corona.\n",
      "3 .  RT @MDR_SN: # Corona ticker #Saxony in the evening: further deaths in nursing home in #Radeberg +++ household lock also in #Zwickau https: //t.…\n",
      "4 .  before corona      vs     while corona https://t.co/n314gavpDl\n",
      "5 .  RT @Oliseh_King: Corona virus really streaming on all platforms\n",
      "6 .  The staff of the Käuber Räuberbande in Hemer wrote poems for the parents and children. We have a little outlook ... https://t.co/tnoQDQ92SG\n",
      "7 .  RT @dani_draco_: Corona be full finesse\n",
      "8 .  RT @Divine27371914: Hey rap fans, I feel like corona isn’t out there. Kao🇸🇱needs to come again. I analyzed this shit and what LJ did was fl…\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tweetJSON = {}\n",
    "\n",
    "with open('./result.json' , encoding='utf-8') as J:\n",
    "    tweetJSON = json.loads(J.read())\n",
    "    \n",
    "tweets = tweetJSON['response']['tweets']\n",
    "\n",
    "tweet_texts = []\n",
    "\n",
    "for index,tweet in enumerate(tweets):\n",
    "    print( index ,\". \" , tweet['text'] )\n",
    "    tweet_texts.append(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1a4fae9d505b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1836\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1837\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1210\u001b[0;31m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m                 \"string object received.\")\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=1,\n",
    "    min_df=1,\n",
    "    max_features=None,\n",
    "    ngram_range=(1, 2),\n",
    "    norm=None,\n",
    "    binary=True,\n",
    "    use_idf=False,\n",
    "    sublinear_tf=False\n",
    ")\n",
    "\n",
    "vectorizer = vectorizer.fit(tweet['text'])\n",
    "\n",
    "tfidf = vectorizer.transform(tweet['text'])\n",
    "\n",
    "input_text = vectorizer.get_feature_names()\n",
    "\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-0e0ce30da784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/nlp/lib/python3.7/site-packages/corextopic/corextopic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/lib/python3.7/site-packages/corextopic/corextopic.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, details)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mp_y_given_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_y_given_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/lib/python3.7/site-packages/corextopic/corextopic.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"Data can be binary or can be in the range [0,1], where that is interpreted as the probability to\n\u001b[1;32m    258\u001b[0m         see this variable in a given sample\"\"\"\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binarize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "model.predict(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
